{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://raw.githubusercontent.com/dvgodoy/PyTorch101_ODSC_Europe2020/master/images/linear_dogs.jpg\" width=\"800\"> \n",
    "</center>  \n",
    "\n",
    "# Yet another math for DS course: домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ФИО:**\n",
    "\n",
    "**Любимый анекдот:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общая информация\n",
    "\n",
    "\n",
    "__Дата выдачи:__ 20.11.2023\n",
    "\n",
    "__Мягкий дедлайн:__ 23:59MSK 10.12.2023\n",
    "\n",
    "__Жёсткий дедлайн:__ 23:59MSK 17.12.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формат сдачи\n",
    "\n",
    "Сам ноутбук называйте в формате hw-02-USERNAME.ipynb, где USERNAME — ваши фамилия и имя. Файл надо будет сдать в anytask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это домашнее задание состоит из двух частей: \n",
    "\n",
    "- Часть с кодом\n",
    "- Часть с ручными задачами\n",
    "\n",
    "Часть с кодом должна быть оформлена на в юпитерской тетрадке. Весь код необходимо писать на python.\n",
    "\n",
    "Ручную часть можно решать на бумаге и оформить в виде отсканированной pdf-ки с разборчивым почерком. Можно вбить решение в виде формул прямо в юпитерскую тетрадку, можно сделать pdf-ку в техе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: ручная\n",
    "\n",
    "За эту часть можно набрать 50 баллов.\n",
    "\n",
    "Условия задач [лежат по ссылке](https://github.com/FUlyankin/yet_another_math_for_DS/tree/main/hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: пишем код\n",
    "\n",
    "За эту часть вы можете получить 50 обычных баллов и ещё 15 бонусных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача №1: 50 оттенков градиентного спуска (20 баллов)\n",
    "\n",
    "В этом задании вам предстоит реализовать линейный классификатор и натренировать его, используя различные модификации градинетного спуска. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для наших целей будем использовать искуственно сгенерированные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing\n",
    "\n",
    "# keep random_state=42 for deterministic results\n",
    "(X, y) = datasets.make_circles(n_samples=1024, shuffle=True, noise=0.2, factor=0.4, random_state=42)\n",
    "ind = np.logical_or(y == 1, X[:, 1] > X[:, 0] - 0.5)\n",
    "X = X[ind, :]\n",
    "m = np.array([[1, 1], [-2, 1]])\n",
    "X = preprocessing.scale(X)\n",
    "y = y[ind]\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__ Как вы можете заметить, данные не являются линейно разделимыми. Нам придётся добавить в обучающую выборку новые фичи либо использовать нелинейные модели. Предположим, что разделяющая поверхность имеет вид окружности. Добавьте в матрицу признаков дополнительные колонки $x_1^2$, $x_2^2$ и $x_1 \\cdot x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(X):\n",
    "    \"\"\"\n",
    "    Добавляет квадратичные фичи. \n",
    "    Для каждой строки матрицы находит строку \n",
    "    [feature0, feature1, feature0^2, feature1^2, feature0*feature1, 1]\n",
    "    \n",
    "    :param X: матрица фичей, shape [n_samples,2]\n",
    "    :returns: расширенная матрица фичей, shape [n_samples,6]\n",
    "    \"\"\"\n",
    "\n",
    "    # your code here\n",
    "    # ヽ(♡‿♡)ノ\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__ Для классификации будем использовать логистическую регрессию. \n",
    "\n",
    "$$ a(x; w) = \\langle w, x \\rangle $$\n",
    "$$ P( y=1 \\; \\big| \\; x, \\, w) = \\dfrac{1}{1 + \\exp(- \\langle w, x \\rangle)} = \\sigma(\\langle w, x \\rangle)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(X, w):\n",
    "    \"\"\"\n",
    "    Принимает на вход матрицу фичей и вектор весов\n",
    "    Возвращает предсказание вероятность того, что y = 1 при фиксированных x, P(y=1|x)\n",
    "    \n",
    "    :param X: расширенная матрица фичей [n_samples,6] (expanded)\n",
    "    :param w: вектор весов [6]\n",
    "    :returns: вектор вероятностей\n",
    "    \"\"\"\n",
    "\n",
    "    # your code here\n",
    "    # ฅ^•ﻌ•^ฅ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__ Для логистической регрессии оптимальный параметр находится минимизацией кросс-энтропии: \n",
    "\n",
    "$$ L(w) =  - {1 \\over \\ell} \\sum_{i=1}^\\ell \\left[ {y_i \\cdot log P(y_i = 1 \\, | \\, x_i,w) + (1-y_i) \\cdot log (1-P(y_i = 1 \\, | \\, x_i,w))}\\right] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, y, w):\n",
    "    \"\"\"\n",
    "    Принимает на вход матрицу весов, вектор ответов и вектор весов.\n",
    "    Выдаёт на выход значение функции потерь, расчитанное по формуле выше.\n",
    "    \"\"\"\n",
    "\n",
    "    # your code here\n",
    "    # (♡-_-♡) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__ Мы будем обучать модель методом градиентного спуска. Для этого нам придётся вычислить градиент функции потерь, представленной выше. Возьмите листочек, ручку и в бой! \n",
    "\n",
    "$$ \\nabla_w L = ...$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(X, y, w):\n",
    "    \"\"\"\n",
    "    Нахоит значение градиента.\n",
    "    \"\"\"\n",
    "\n",
    "    # your code here\n",
    "    # (´｡• ᵕ •｡`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже предназначена для визуализации процесса обучения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "h = 0.01\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "def visualize(X, y, w, history):\n",
    "    \"\"\"С помощью магии matplolib выдаёт красоты результатов классификации\"\"\"\n",
    "    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history)\n",
    "    plt.grid()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.ylim(0, ymax)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убедитесь, что у вас она работает, запустив код ниже \n",
    "# (он отработает если вы верно реализовали expend и probability)\n",
    "dummy_weights = np.linspace(-1, 1, 6)\n",
    "visualize(X, y, dummy_weights, [0.5, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пришло время обучить нашу модель. Для этого вам придётся дописать кусочки функций ниже. Обязательно попробуйте поменять гиперпараметры (размер батча и скорость обучения) и посмотреть как будет изменяться анимация. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __[4 балла]__ Mini-batch SGD\n",
    "\n",
    "Берём несколько рандомных наблюдений и ищем градиент по ним! \n",
    "\n",
    "$$ w_t = w_{t-1} - \\eta \\dfrac{1}{m} \\sum_{j=1}^m \\nabla_w L(w_t, x_{i_j}, y_{i_j}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "eta = 0.05 \n",
    "alpha = 0.9 \n",
    "nu = np.zeros_like(w)\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in range(n_iter):\n",
    "    \n",
    "    # your code here\n",
    "    # ヾ(๑╹◡╹)ﾉ\n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __[4 балла]__ Momentum SGD\n",
    "\n",
    "Momentum это метод, который помогает стохастическому градиентному спуску сохранять направление движения. Это осуществляется за счёт добавления в выражение дополнительного слагаемого: накопленного за предыдущие шаги градиента с весом $\\alpha$. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$ \\nu_t = \\alpha \\nu_{t-1} + \\eta\\dfrac{1}{m} \\sum_{j=1}^m \\nabla_w L(w_t, x_{i_j}, y_{i_j}) $$\n",
    "$$ w_t = w_{t-1} - \\nu_t$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "eta = 0.05 \n",
    "alpha = 0.9 \n",
    "nu = np.zeros_like(w)\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in range(n_iter):\n",
    "    \n",
    "    # your code here\n",
    "    # ٩(ˊ〇ˋ*)و\n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __[4 балла]__ RMSprop\n",
    "\n",
    "В этом блоке реализуем RMSprop. Эта вариация градиентного спуска позволяет изменять скорость обучения индивидуально для каждого параметра. \n",
    "\n",
    "$$ G_t^j = \\alpha G_{t-1}^j + (1 - \\alpha) g_{tj}^2 $$\n",
    "$$ w_t^j = w_{t-1}^j - \\dfrac{\\eta}{\\sqrt{G_t^j + \\varepsilon}} g_{tj} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "w = np.array([0, 0, 0, 0, 0, 1.])\n",
    "\n",
    "eta = 0.1 \n",
    "alpha = 0.9 \n",
    "g2 = np.zeros_like(w)\n",
    "eps = 1e-8\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(n_iter):\n",
    "\n",
    "    # your code here\n",
    "    # (っ˘ڡ˘ς) \n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[бонусные 5]__ Реализуйте Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# (⌒_⌒;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[бонусные 5]__ Выясните что такое метод Ньютона (метод второго порядка) и реализуйте его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# ༼ つ ಥ_ಥ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[бонусные 5]__ Выясните, что такое weight decay и реализуйте его для базовой версии SGD. Правда ли, что эта модернизация улучшает обучение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# ( ￣ー￣)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача №2: SVD (30 баллов)\n",
    "\n",
    "Напомним, что сингулярным разложением (SVD, Singular value decomposition) матрицы $A$ размера $m\\times n$ называется представление\n",
    "\n",
    "$$A = U\\Sigma V^T,$$\n",
    "\n",
    "где $U$ — ортогональная матрица размера $m\\times m$, $V$ — ортогональная матрица размера $n\\times n$, $\\Sigma = \\mathrm{diag}(\\sigma_1,\\sigma_2,\\sigma_3,\\ldots)$ — диагональная матрица размера $m\\times n$, в которой $\\sigma_1\\geqslant\\sigma_2\\geqslant\\ldots\\geqslant0$.\n",
    "\n",
    "На самом деле требование, чтобы матрицы $U$ и $V$ были квадратными, избыточно. *Усечённым сингулярным разложением* мы будем называть разложение\n",
    "\n",
    "$$A = U\\Sigma V^T,$$\n",
    "\n",
    "где $U$ и $V$ — матрицы с ортонормированными столбцами размеров $m\\times k$ и $n \\times k$ соответственно, $\\Sigma$ — диагональная матрица размера $k\\times k$, где $k = \\min(m,n)$. Далее мы будем работать исключительно с усечённым разложением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сжатие данных с помощью SVD = построение низкорангового приближения\n",
    "\n",
    "Введём *норму Фробениуса* матрицы как\n",
    "\n",
    "$$||A||_{frob} = \\sqrt{\\mathrm{tr}{A^TA}} = \\sqrt{\\sum\\limits_{i,j}a^2_{i,j}}$$\n",
    "\n",
    "Иными словами, это обычное евклидово расстояние на пространстве, которое получается, если все матрицы вытянуть в длинные векторы.\n",
    "\n",
    "Зададимся вопросом: как найти матрицу $A_{r}$ ранга $r$, наименее отличающуюся от $A$ по норме Фробениуса (то есть для которой норма разности $||A - A_{r}||_{frob}$ минимальна). Оказывается, это можно сделать с помощью сингулярного разложения:\n",
    "\n",
    "**Теорема.** Пусть $\\Sigma_{r}$ — это матрица, полученная из $\\Sigma$ заменой диагональных элементов $\\sigma_{i}$ ($i > r$) нулями, тогда $A_{r} = U\\Sigma_{r}V^T$.\n",
    "\n",
    "Это можно переписать и в более экономичном виде. Если\n",
    "\n",
    "$$A = \\underbrace{\n",
    "\\begin{pmatrix}\n",
    "u_{11} & \\ldots & u_{1k}\\\\\n",
    "\\vdots & & \\vdots\\\\\n",
    "u_{m1} & \\ldots & u_{mk}\n",
    "\\end{pmatrix}}_{=U}\\cdot\\underbrace{{\n",
    "\\begin{pmatrix}\n",
    "\\sigma_{1} & &\\\\\n",
    " & \\sigma_{2} & \\\\\n",
    " & & \\ddots\n",
    "\\end{pmatrix}}\n",
    "}_{=\\Sigma}\\cdot \\underbrace{\n",
    "\\begin{pmatrix}\n",
    "v_{11} & \\ldots & v_{n1}\\\\\n",
    "\\vdots & & \\vdots\\\\\n",
    "v_{1k} & \\ldots & v_{nk}\n",
    "\\end{pmatrix}}_{=V^T}$$\n",
    "\n",
    "то\n",
    "\n",
    "$$A_{r} = \\underbrace{\n",
    "\\begin{pmatrix}\n",
    "u_{11} & \\ldots & u_{1r}\\\\\n",
    "\\vdots & & \\vdots\\\\\n",
    "u_{m1} & \\ldots & u_{mr}\n",
    "\\end{pmatrix}}_{=U_r}\\cdot\\underbrace{{\n",
    "\\begin{pmatrix}\n",
    "\\sigma_{1} & &\\\\\n",
    " & \\ddots & \\\\\n",
    " & & \\sigma_{r}\n",
    "\\end{pmatrix}}\n",
    "}_{=\\Sigma_r}\\cdot \\underbrace{\n",
    "\\begin{pmatrix}\n",
    "v_{11} & \\ldots & v_{n1}\\\\\n",
    "\\vdots & & \\vdots\\\\\n",
    "v_{1r} & \\ldots & v_{nr}\n",
    "\\end{pmatrix}}_{=V^T_r}$$\n",
    "\n",
    "При этом\n",
    "\n",
    "$$||A - A_{r}||_{frob} = \\sqrt{\\sum\\limits_{i\\geqslant r+1} \\sigma_{i}^2}$$\n",
    "\n",
    "Если сингулярные значения матрицы падают достаточно быстро (а в реальных задачах часто бывает именно так), то норма разности будет малой при сравнительно небольшом значении $r$.\n",
    "\n",
    "На хранение исходной матрицы нам требовалось $m\\times n$ памяти. Теперь же, если мы будем хранить отдельно $U_r$, $V_r$ и диагональные элементы $\\Sigma_r$, затраты памяти составят $mr + nr + r = r(m + n + 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разложение на компоненты ранга 1**\n",
    "\n",
    "Обозначим через $u_1,\\ldots, u_k$ столбцы матрицы $U$, а через $v_1, \\ldots, v_k$ столбцы матрицы $V$. Тогда имеет место равенство\n",
    "\n",
    "$$A = u_1\\sigma_{1}v_1^T + u_2\\sigma_{2}v_2^T + u_3\\sigma_{3}v_3^T + \\ldots$$\n",
    "\n",
    "Матрицу $u_k\\sigma_{k}v_k^T = \\sigma_{k}u_kv_k^T$ мы будем называть $k$-й компонентой ранга 1 матрицы $A$. Отметим, что слагаемые в этой сумме ортогональны относительно скалярного произведения $(X, Y) = \\mathrm{tr}(X^TY)$ (порождающего норму Фробениуса).\n",
    "\n",
    "Как нетрудно заметить,\n",
    "\n",
    "$$A_{r} = \\sigma_{1}u_1v_1^T + \\sigma_{2}u_2v_2^T + \\ldots + \\sigma_{r}u_rv_r^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Геометрический смысл SVD**\n",
    "\n",
    "Допустим, что у нас есть выборка $x_1,\\ldots,x_m\\in\\mathbb{R}^n$. Запишем её в матрицу объекты-признаки\n",
    "\n",
    "$$X = \\begin{pmatrix}\n",
    "x_{11} & \\ldots & x_{1n}\\\\\n",
    "\\vdots & & \\vdots\\\\\n",
    "x_{m1} & \\ldots & x_{mn}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "(строки — объекты, столбцы — признаки) и сделаем SVD-разложение: $X = U\\Sigma V^T$. Его можно интерпретировать следующим образом:\n",
    "\n",
    "$$X = U\\Sigma\\cdot V^T,$$\n",
    "\n",
    "где $U\\Sigma$ — это матрица объекты-признаки для тех же объектов, но в новых признаках, полученных из исходных с помощью линейного преобразования $V$ (напоминаем, что умножение на матрицу справа соответствует преобразованию столбцов). Попробуем понять, чем замечательны эти признаки.\n",
    "\n",
    "Рассмотрим матрицу $X^TX = V\\Sigma^2V^T$. Легко видеть, что это матрица Грама системы столбцов матрицы $X$; иными словами, в ней записаны скалярные произведения векторов различных признаков. Из лекций вы знаете, что $\\sigma_1^2$, квадрат первого сингулярного числа, это наибольшее собственное значение матрицы $X^TX$, а $v_1$, первый столбец матрицы $V$, — это соответствующий собственный вектор. Можно показать, что\n",
    "\n",
    "$$\\sigma_1 = \\mathrm{max}_{w}\\frac{|Xw|}{|w|} = \\mathrm{max}_{|w| = 1}\\left(|Xw|\\right).$$\n",
    "\n",
    "Попробуем осознать физический смысл этой штуки. Напомним, что строки матрицы $X$ — это координаты объектов $x_1,\\ldots,x_m$ в пространстве признаков. Произведение $Xw$ — это вектор из значений на тех же самых объектах некоторого нового признака, являющегося линейной комбинацией исходных с коэффициентами $w_1,\\ldots,w_n$:\n",
    "\n",
    "$$Xw = w_1\\begin{pmatrix} x_{11}\\\\ \\ldots \\\\ x_{m1}\n",
    "\\end{pmatrix} + w_2\\begin{pmatrix} x_{12}\\\\ \\ldots \\\\ x_{m2}\n",
    "\\end{pmatrix} + \\ldots + w_n\\begin{pmatrix} x_{1n}\\\\ \\ldots \\\\ x_{mn}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Соответственно, $|Xw|^2$ — это квадрат длины вектора, составленного из значений нового признака.\n",
    "\n",
    "Таким образом, первому сингулярному значению $\\sigma_1$ отвечает такой признак, у которого сумма квадратов значений максимальна, то есть признак, принимающий, условно говоря, самые большие значения.\n",
    "\n",
    "Резюмируя, мы можем сказать, что сингулярное разложение делает следующее:\n",
    "- находит новый признак (новое направление) вдоль которого \"дисперсия\" максимальна;\n",
    "- в ортогональной ему плоскости находит признак, вдоль которого \"дисперсия\" максимальна;\n",
    "- и так далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Технические детали (SVD в Питоне)**\n",
    "\n",
    "Есть несколько способов сделать в Питоне сингулярное разложение; мы пока предлагаем Вам использовать\n",
    "\n",
    "`import scipy.linalg as sla`\n",
    "\n",
    "`U, S, Vt = sla.svd(X, full_matrices=False)`\n",
    "\n",
    "Для ознакомления с особенностями этой функции рекомендуем обратиться к [документации](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html) (в частности, обратите внимание на то, какие именно объекты она возвращает)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем поработать с какой-нибудь картинкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "img = cv.imread(\"data/chain_small.jpg\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.mean(axis=2) # это матрица из интенсивностей серого цвета; её уже можно подвергать SVD\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем картинку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "imgplot = plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим сингулярное разложение этой матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "\n",
    "U, S, VT = svd(img, full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[4 балла]__ Нарисуйте график диагональных элементов матрицы $\\Sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# ʕ•ᴥ•ʔ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что они убывают достаточно быстро и есть надежда, что первые несколько компонент дадут картинку, близкую к исходной.\n",
    "\n",
    "**Важно:** при визуализации различных компонент в этом задании используйте только матричные операции. В частности, избегайте циклов, функций `map` и `reduce`, а также специальных функций, находящих суммы компонент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[4 балла]__ Визуализуйте первую компоненту ранга 1. Ожидали ли Вы увидеть именно это? Поясните."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# [✖‿✖]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[4 балла]__  Визуализуйте суммы компонент ранга 1 с первой по двадцатую, с первой по пятидесятую, с двадцатой по сотую, с двадцатой по последнюю. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# ┌(ಠ_ಠ)┘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__  Как Вам кажется, какие компоненты нужно взять для достаточно хорошего восстановления исходного изображения? Аргументируйте свой ответ. Не забудьте визуализировать сумму выбранных компонент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Комментарий: для получения полного балла за это задания постарайтесь привести более убедительный аргумент, нежели Ваши субъективные впечатления от сравнения полученного изображения с исходным.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Ответ:__ Ваш ответ буквами прям в маркдауне:3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# ( .-. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__ Во сколько раз меньше памяти (теоретически) потребуется для хранения нового изображения по сравнению с исходным?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Ответ:__ Ваш ответ буквами прям в маркдауне:3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1 балл]__ Подсчитайте, сколько в действительности места в памяти компьютера занимают исходная матрица и компоненты её сингулярного разложения. Согласуется ли этот результат с ответом предыдущего пункта? Сделайте выводы.\n",
    "\n",
    "_Hint:_ достаточно сохранить да файла на компьютер в `.np` формате и сравнить их вес между собой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Ответ:__ Ваш ответ буквами прям в маркдауне:3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые из \"новых\" признаков — это признаки, значения которых, скажем так, наиболее разнообразны. Зачастую (хотя и не всегда) именно они несут в себе наиболее важные черты датасета. И если взять два-три первых, то датасет можно нарисовать и посмотреть на него — и, возможно, обнаружить какую-то структуру.\n",
    "\n",
    "С помощью функции `dsklearn.datasets.load_digits()` загрузите датасет рукописных цифр [MNIST](http://yann.lecun.com/exdb/mnist/). В нём есть несколько атрибутов; вам сейчас будут нужны `digits.data` (`np.array`, строки которого — это вытянутые в одну строку значения пикселей) и `digits.target` (в них записаны соответствующие цифры)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "print(digits.target[0])\n",
    "\n",
    "plt.imshow(digits.data[0].reshape((8,8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[3 балла]__ Примените к матрице `digits.data` сингулярное разложение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# (⌐■_■)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__  Визуализируйте данные, спроецировав их на такую плоскость, чтобы координаты точек соответствовали первым двум новым признакам. Не забудьте покрасить точки, отвечающие различным цифрам, в разные цвета (если Вы любите красивые визуализации, разберитесь, как вместо точек рисовать маленькие цифры)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# (❍ᴥ❍ʋ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__  Теперь вычтите из каждого признака его среднее значение, снова сделайте SVD и нарисуйте разноцветные точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# [̲̅$̲̅(̲̅5̲̅)̲̅$̲̅]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[2 балла]__  Сравните выполненные Вами в двух предыдущих пунктах визуализации. Чем последняя выгодно отличается от первой?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#  ლ(ಠ益ಠლ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[4 балла]__  Сравните работу SVD с другим методом понижения размерности: [случайными гауссовскими проекциями](http://scikit-learn.org/stable/modules/generated/sklearn.random_projection.GaussianRandomProjection.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# ヾ(๑╹◡╹)ﾉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Комментарий: Эксперименты без выводов, объясняющих полученные результаты, не оцениваются. Для получения полного балла за этот пункт постарайтесь провести как можно больше разноплановых экспериментов.*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
